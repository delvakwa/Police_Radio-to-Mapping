{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install google\n",
    "# ! pip install --user google.cloud\n",
    "# ! pip install --user google.cloud.speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/Pickles/streets.pkl\", \"rb\") as fp:\n",
    "    streets = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool is a class in the multiprocessing package that distributes functionality across multiple processes in a computer. Simply put, it lets the computer assign more than one person to build a fence instead of 1. This dramatically speeds up the time it takes for computationally expensive tasks to run and it called and placed around such tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = #Insert API key here\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../audio_data/audio_files/wav_files/10904-20190730-1657_1.wav',\n",
       " '../audio_data/audio_files/wav_files/10904-20190730-1657_10.wav',\n",
       " '../audio_data/audio_files/wav_files/10904-20190730-1657_11.wav']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../audio_data/audio_files/wav_files/'\n",
    "wav_file = []\n",
    "for filename in os.listdir(path)[1:]:\n",
    "    wav_file.append(path + filename)\n",
    "wav_file[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google’s Speech to Text API accepts a wav file and stores it into memory. When calling the speech to text API, we can pass in a dictionary for it to reference its results on. We decided to run the API with and without street context to see if which setting would provide better results. The API then proceeds to detect speech in the audio file and return a transcription of what it heard and it’s confidence in the results. We returned those results as a dataframe. \n",
    "\n",
    "## With Street Name Context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_context(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\",\n",
    "        speech_contexts = [{\n",
    "                        \"phrases\": np.random.choice(streets, 5000)\n",
    "                         }]\n",
    "    )\n",
    "    \n",
    "    #Detects speech in audio file\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(1)\n",
    "    return transcript, confidence, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts_context = pool.map(speech_to_text_context, wav_file)\n",
    "\n",
    "captions_context = [a[0] for a in list_of_transcripts_context if a[0] != '']\n",
    "confidence_context = [a[1] for a in list_of_transcripts_context if a[0] != '']\n",
    "\n",
    "data_context = {'transcripts': captions_context, \n",
    "                'confidence': confidence_context}\n",
    "df_context = pd.DataFrame(data_context)\n",
    "# df_context.to_csv('../data/Data/transcribed_radio_with_street_context.csv')\n",
    "df_context.head(25)\n",
    "    \n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7664087745878432"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_context['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Street Name Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\"\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file    \n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return transcript, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was just</td>\n",
       "      <td>0.502997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our brothers are critical for 1636 thank you</td>\n",
       "      <td>0.842904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is going to be</td>\n",
       "      <td>0.652573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to drive robson's plane set the driver knocked...</td>\n",
       "      <td>0.700766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Market 11:30 high was 31130 hi</td>\n",
       "      <td>0.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drat or kind of somebody can price and stay fa...</td>\n",
       "      <td>0.772701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peridot we close races here</td>\n",
       "      <td>0.680532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Library 612 Smithfield Street between 6th Aven...</td>\n",
       "      <td>0.839220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>down there markets weren't</td>\n",
       "      <td>0.785316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transcripts  confidence\n",
       "0                                         I was just    0.502997\n",
       "1       our brothers are critical for 1636 thank you    0.842904\n",
       "2                                     is going to be    0.652573\n",
       "3  to drive robson's plane set the driver knocked...    0.700766\n",
       "4                     Market 11:30 high was 31130 hi    0.803496\n",
       "5  drat or kind of somebody can price and stay fa...    0.772701\n",
       "6                        Peridot we close races here    0.680532\n",
       "7  Library 612 Smithfield Street between 6th Aven...    0.839220\n",
       "8                         down there markets weren't    0.785316"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts = pool.map(speech_to_text, wav_file)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "captions = [a[0] for a in list_of_transcripts if a[0] != '']\n",
    "confidence = [a[1] for a in list_of_transcripts if a[0] != '']\n",
    "names = [a[2] for a in list_of_transcripts if a[0] != '']\n",
    "\n",
    "data = {'transcripts': captions, \n",
    "        'confidence': confidence}\n",
    "df = pd.DataFrame(data)\n",
    "# df.to_csv('../data/Data/transcribed_radio.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7311672965685526"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Code adapted from [NY General Assembly DSI radio-to-location repository](https://github.com/mchbmn/radio-to-location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
