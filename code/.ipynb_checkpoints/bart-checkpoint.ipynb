{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "# import weakref\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from IPython.display import clear_output\n",
    "from time import time as timer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import wait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "FEED_URL_STEM = 'https://www.broadcastify.com/listen/feed/'\n",
    "ARCHIVE_URL_STEM = 'https://m.broadcastify.com/archives/feed/'\n",
    "LOGIN_URL = 'https://www.broadcastify.com/login/'\n",
    "MAIN_URL = 'https://www.broadcastify.com/'\n",
    "\n",
    "WEBDRIVER_PATH = '../assets/chromedriver'\n",
    "\n",
    "FILE_REQUEST_WAIT = 3 # seconds\n",
    "PAGE_REQUEST_WAIT = 1 # seconds\n",
    "\n",
    "MONTHS = ['','January', 'February', 'March',\n",
    "      'April', 'May', 'June',\n",
    "      'July', 'August', 'September',\n",
    "      'October', 'November', 'December']\n",
    "\n",
    "# Library-level variables\n",
    "ArchiveEntry = collections.namedtuple('ArchiveEntry',\n",
    "                                     'file_uri file_end_date_time mp3_url')\n",
    "\"\"\"\n",
    "file_uri : str\n",
    "    The unique ID for an individual archive file, which corresponds to a feed's \n",
    "    transmission over a ~30-minute period on a given date. Can be used to find \n",
    "    the file's individual download page\n",
    "file_end_date_time : str\n",
    "    Date and end time of the transmission in the format YYYYMMDD-HHMM, on a \n",
    "    24-hour clock\n",
    "mp3_url : str\n",
    "    The URL of the corresponding mp3 file\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BroadcastifyFeed:\n",
    "    def __init__(self, feed_id, username=None, password=None):\n",
    "        # Attributes\n",
    "        self.id = feed_id\n",
    "        self.url = FEED_URL_STEM + feed_id\n",
    "        self.archive_url = ARCHIVE_URL_STEM + feed_id\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.is_logged_in = False\n",
    "        self.last_page_request_time = timer()\n",
    "        self.last_file_request_time = timer()\n",
    "        self.browser = webdriver.Chrome('../assets/chromedriver')\n",
    "#         self.archive = Archive(self)\n",
    "        self.archive = None\n",
    "        \n",
    "        # Properties\n",
    "        @property\n",
    "        def username(self):\n",
    "            \"\"\"Username for Broadcastify premium account.\"\"\"\n",
    "            print('Inside property construct.')\n",
    "            return self.username\n",
    "        @username.setter\n",
    "        def username(self, value):\n",
    "            self.username = value\n",
    "            print('Inside property construct.')\n",
    "\n",
    "        @property\n",
    "        def password(self):\n",
    "            \"\"\"Password for Broadcastify premium account.\"\"\"\n",
    "            if self.__password:\n",
    "                print('Inside property construct.')\n",
    "                return True\n",
    "            else:\n",
    "                print('Inside property construct.')\n",
    "                return False\n",
    "        @password.setter\n",
    "        def password(self, value):\n",
    "            self.__password = value\n",
    "            print('Inside property construct.')\n",
    "\n",
    "#        # For future implementation\n",
    "#         self.genre = None\n",
    "#         self.listeners = None\n",
    "#         self.status = None\n",
    "#         self.description = None\n",
    "#         self.notes = None\n",
    "\n",
    "    def build_archive(self, days_back=-1):\n",
    "        archive_builder = Archive()\n",
    "        \n",
    "    def courtesy_wait(self, request_type='Page'):\n",
    "        if type == 'File':\n",
    "            while timer() - self.last_file_request_time <= FILE_REQUEST_WAIT:\n",
    "                pass\n",
    "            last_file_request_time = timer()\n",
    "        else:\n",
    "            while timer() - self.last_page_request_time <= PAGE_REQUEST_WAIT:\n",
    "                pass\n",
    "            last_page_request_time = timer()\n",
    "        \n",
    "    def login(self):\n",
    "        self.last_page_request_time = timer()\n",
    "        self.browser.get(LOGIN_URL)\n",
    "\n",
    "        ## Store the fields for username + password\n",
    "        username_field = self.browser.find_element_by_id(\"uname\") \n",
    "        password_field = self.browser.find_element_by_name(\"password\")\n",
    "\n",
    "        ## Type username + password, and hit \"enter\"\n",
    "        username_field.send_keys(USERNAME)\n",
    "        password_field.send_keys(PASSWORD)\n",
    "        password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "        ## Wait for login to complete\n",
    "        self.browser.implicitly_wait(2)\n",
    "        \n",
    "        ## Check that the login was successful\n",
    "        if self.browser.current_url == MAIN_URL:\n",
    "            is_logged_in = True\n",
    "        else:\n",
    "            is_logged_in = False\n",
    "            raise ConnectionError('Login failed: please check username and password.')\n",
    "    \n",
    "    def __del__(self):\n",
    "        print(\"Delete method called.\")\n",
    "        self.browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "code_folding": [
     46,
     49,
     93,
     97
    ]
   },
   "outputs": [],
   "source": [
    "class Archive:\n",
    "    def __init__(self, parent):\n",
    "        self.parent = parent\n",
    "        self.archive_times_table = None # to interact with archivetimes table        \n",
    "        self.archive_times_navigator = None # to navigate the \"archive times\" over multiple dates\n",
    "        self.url = ARCHIVE_URL_STEM + parent.id\n",
    "        self.entries = [] # list of ArchiveEntry objects\n",
    "        self.earliest_date = None \n",
    "        self.latest_date = None\n",
    "        \n",
    "        self.archive_page_soup = None # make this private\n",
    "\n",
    "    def build(self, days_back=0): # 0 days back means the active day\n",
    "        \n",
    "        all_timestable_entries = []\n",
    "        all_mp3_paths = []\n",
    "        \n",
    "#         # Open the archive's navigation page\n",
    "#         parent.courtesy_wait()\n",
    "#         parent.browser.get(self.url)\n",
    "        \n",
    "#         # Wait for page to render\n",
    "#         element = WebDriverWait(parent.browser, 10).until(\n",
    "#                   EC.presence_of_element_located((By.CLASS_NAME, \"cursor-link\")))\n",
    "\n",
    "#         # Capture page content as a BSoup\n",
    "#         self.archive_page_soup = BeautifulSoup(parent.browser.page_source, 'lxml')\n",
    "        \n",
    "        # Populate the CalendarNavigator and the ArchiveTimesTable\n",
    "#         self.archive_times_table = ArchiveTimesTable(self, self.archive_page_soup)\n",
    "        self.calendar = ArchiveTimesNavigator()\n",
    "        \n",
    "\n",
    "        # Adjust days back, since loops start at 1\n",
    "        days_back += 1\n",
    "        \n",
    "        # Ensure the \"active day\" is selected on the calendar\n",
    "        \n",
    "        # For each day requested...\n",
    "        for day in range(days_back):\n",
    "            pass\n",
    "        \n",
    "        # Get the mp3 file URLs\n",
    "        \n",
    "        # Put uri, end date, & URL into an ArchiveEntry, and make a list of all of them\n",
    "\n",
    "    def get_mp3_files(self, start_date=-1, end_date=-1, time_of_day=-1):\n",
    "        pass\n",
    "    \n",
    "    def __parse_timestable(self):\n",
    "        \"\"\"\n",
    "        Generates a list of Broadcastify archive file information from\n",
    "        the `archiveTimes` table on a feed's archive page. Each item in\n",
    "        the list is a list of two elements:\n",
    "            - The unique ID for the file, which can be used to find the file's\n",
    "              individual download page\n",
    "            - Date and end time of the transmission in the format YYYYMMDD-HHMM,\n",
    "              on a 24-hour clock\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self.soup : bs4.BeautifulSoup\n",
    "            A BeautifulSoup object containing the feed archive page source code, \n",
    "            e.g. from https://m.broadcastify.com/archives/feed/[feed_id]\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        # Set up a blank list to return\n",
    "        timestable_entries = []\n",
    "\n",
    "        # Isolate the `archive_times` table body\n",
    "        archive_times = self.soup.find('table', attrs={'id': 'archiveTimes'}).find('tbody')\n",
    "\n",
    "        # Find the date of transmission of the archived files\n",
    "        archive_date = self.__format_archive_date()\n",
    "\n",
    "        # Loop through all rows of the table\n",
    "        for row in archive_times.find_all('tr'):\n",
    "\n",
    "            # Grab the end time, contained in the row's second <td> tag\n",
    "            file_end_time = self.__time_to_hhmm(row.find_all('td')[1].text) \n",
    "\n",
    "            # Represent the date & end time of the file as YYYYMMDD-HHMM\n",
    "            file_end_date_time = '-'.join([archive_date, file_end_time])\n",
    "\n",
    "            # Grab the file ID\n",
    "            file_uri = row.find('a')['href'].split('/')[-1]\n",
    "\n",
    "            # Put the file date/time and URL leaf (as a list) into the list\n",
    "            timestable_entries.append([file_uri, file_end_date_time])\n",
    "        \n",
    "        return timestable_entries\n",
    "    \n",
    "    def parse_mp3_path(download_page_soup):\n",
    "        # Get the filepath for the mp3 archive\n",
    "        return download_page_soup.find('a', {'href': re.compile('.mp3')}).attrs['href']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArchiveTimesNavigator:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.calendar_soup = None\n",
    "        self.archive_times_soup = None\n",
    "\n",
    "        self.active_date = None # currently displayed date\n",
    "        self.month_max_date = None # latest day in displayed month with archive entries\n",
    "        self.month_min_date = None # earliest day in displayed month with archive entries\n",
    "        \n",
    "        self.browser = webdriver.Chrome('../assets/chromedriver')\n",
    "\n",
    "        # Get initial page scrape & parse the calendar\n",
    "        self.__load_nav_page()\n",
    "        self.__scrape_nav_page()\n",
    "        self.__parse_calendar()\n",
    "        \n",
    "        self.archive_max_date = self.active_date\n",
    "        \n",
    "        self.archive_min_date = self.archive_max_date - timedelta(days=181)\n",
    "            # https://www.saltycrane.com/blog/2010/10/how-get-date-n-days-ago-python/    \n",
    "        \n",
    "    def click_prior_day(self):\n",
    "        # calculate the prior day\n",
    "        prior_day = self.active_date - timedelta(days=1)\n",
    "        \n",
    "        # would this take us past the archive? if so, stop.\n",
    "        if prior_day < self.archive_min_date:\n",
    "            return False\n",
    "        \n",
    "        # is the prior day in the previous month? set the class appropriately\n",
    "        if prior_day < self.month_min_date:\n",
    "            xpath_class = 'old day'\n",
    "        else:\n",
    "            xpath_class = 'day'\n",
    "        \n",
    "        xpath_day = prior_day.day\n",
    "        \n",
    "        # click the day before the currently displayed day\n",
    "        calendar_day = self.browser.find_element_by_xpath(\n",
    "                        f\"//td[@class='{xpath_class}' \"\n",
    "                        f\"and contains(text(), '{xpath_day}')]\")\n",
    "            # https://stackoverflow.com/questions/2009268/how-to-write-an-xpath-query-to-match-two-attributes\n",
    "        calendar_day.click()\n",
    "\n",
    "        # refresh soup & re-parse calendar\n",
    "        self.__scrape_nav_page()\n",
    "        self.__parse_calendar()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def __load_nav_page(self):\n",
    "        # Browse to feed archive page\n",
    "        self.browser.get(self.url)   \n",
    "    \n",
    "    def __scrape_nav_page(self):\n",
    "        # Wait for page to render\n",
    "        element = WebDriverWait(self.browser, 10).until(\n",
    "                  EC.presence_of_element_located((By.CLASS_NAME, \n",
    "                                                  \"cursor-link\")))\n",
    "\n",
    "        # Scrape page content\n",
    "        soup = BeautifulSoup(self.browser.page_source, 'lxml')\n",
    "\n",
    "        # Isolate the calendar and the archiveTimes table\n",
    "        self.calendar_soup = soup.find('table', \n",
    "                                       {'class': 'table-condensed'})\n",
    "        self.archive_times_soup = soup.find('table', \n",
    "                                            attrs={'id': 'archiveTimes'}\n",
    "                                           ).find('tbody')\n",
    "        \n",
    "\n",
    "    def __parse_calendar(self):\n",
    "        \"\"\"\n",
    "        Uses a bs4 ResultSet of the <td> tags representing days currently displayed\n",
    "        on the calendar to set calendarattributes. Items have the format of \n",
    "        `<td class=\"[class]\">[D]</td>` where \n",
    "         - [D] is the one- or two-digit day (as a string) and\n",
    "         - [class] is one of\n",
    "             \"old day\"          = a day with archives but in a prior month (clicking\n",
    "                                  will refresh the calendar)\n",
    "             \"day\"              = a past day in the current month\n",
    "             \"active day\"       = the day currently displayed in the archiveTimes \n",
    "                                  table\n",
    "             \"disabled day\"     = a day for which no archive is available in a month\n",
    "                                  (past or future) that has other days with archives. \n",
    "                                  For example, if today is July 27, July 28-31 will \n",
    "                                  be disabled days, as will January 1-26 (since the \n",
    "                                  archive goes back only 180 days). December 31 would\n",
    "                                  be an \"old disabled day\".\n",
    "                                  past month for which archives are no longer available\n",
    "             \"new disabled day\" = a day in a future month\n",
    "             \"old disabled day\" = see explanation in \"disabled day\"\n",
    "         \n",
    "        \"\"\"\n",
    "        # Get the tags representing the days currently displayed on the calendar\n",
    "        days_on_calendar = self.calendar_soup.find_all('td')\n",
    "        \n",
    "        # Get the month & year currently displayed\n",
    "        month, year = self.calendar_soup.find('th', \n",
    "                                              {'class': 'datepicker-switch'}\n",
    "                                              ).text.split(' ')\n",
    "        \n",
    "        displayed_month = MONTHS.index(month)\n",
    "        displayed_year = int(year)\n",
    "        \n",
    "        # Parse the various calendar attributes\n",
    "        active_day = int([day.text for day in days_on_calendar\n",
    "                           if (day['class'][0] == 'active')][0])\n",
    "        \n",
    "        month_max_day = int([day.text for day in days_on_calendar\n",
    "                              if (day['class'][0] == 'day') or\n",
    "                                 (day['class'][0] == 'active')][::-1][0])\n",
    "        \n",
    "        month_min_day = int(self.__parse_month_min_day(days_on_calendar))\n",
    "        \n",
    "        # Set class attributes\n",
    "        self.active_date = date(displayed_year, displayed_month, active_day)        \n",
    "        self.month_min_date = date(displayed_year, displayed_month, month_min_day)\n",
    "        self.month_max_date = date(displayed_year, displayed_month, month_max_day)\n",
    "        \n",
    "    def __parse_month_min_day(self, days_on_calendar):\n",
    "        \"\"\"Parse the lowest valid day in the displayed month\"\"\"\n",
    "        disabled_found = False\n",
    "        for day in days_on_calendar:\n",
    "            if day['class'][0] == 'disabled':\n",
    "                disabled_found = True\n",
    "            elif day['class'][0] in 'day active'.split():\n",
    "                return day.text\n",
    "            elif day['class'][0] != 'old' and disabled_found:\n",
    "                return day.text\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(f'ArchiveTimesNavigator(URL: {self.url}, '\n",
    "               f'Currently Displayed: {str(self.active_date)}, '\n",
    "               f'Max Day: {str(self.archive_max_date)}, '\n",
    "               f'Min Day: {str(self.archive_min_date)}, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ArchiveTimesTable:\n",
    "    def __init__(self, parent, archive_page_soup):\n",
    "        self.parent = parent\n",
    "        self.soup = archive_page_soup\n",
    "        self.table_entries = self.__parse_entries()\n",
    "        \n",
    "        # Properties\n",
    "        @property\n",
    "        def table_entries(self):\n",
    "            \"\"\"Username for Broadcastify premium account.\"\"\"\n",
    "            print('Inside property construct.')\n",
    "            return self.table_entries\n",
    "        @table_entries.setter\n",
    "        def table_entries(self, value):\n",
    "            self.table_entries = value\n",
    "            print('Inside property construct.')\n",
    "        \n",
    "#     def __parse_entries(self):\n",
    "#         \"\"\"\n",
    "#         Generates a list of Broadcastify archive file information from\n",
    "#         the `archiveTimes` table on a feed's archive page. Each item in\n",
    "#         the list is a list of two elements:\n",
    "#             - The unique ID for the file, which can be used to find the file's\n",
    "#               individual download page\n",
    "#             - Date and end time of the transmission in the format YYYYMMDD-HHMM,\n",
    "#               on a 24-hour clock\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         self.soup : bs4.BeautifulSoup\n",
    "#             A BeautifulSoup object containing the feed archive page source code, \n",
    "#             e.g. from https://m.broadcastify.com/archives/feed/[feed_id]\n",
    "\n",
    "\n",
    "#         \"\"\"\n",
    "#         # Set up a blank list to return\n",
    "#         table_entry_builder = []\n",
    "\n",
    "#         # Isolate the `archive_times` table body\n",
    "#         archive_times = self.soup.find('table', attrs={'id': 'archiveTimes'}).find('tbody')\n",
    "\n",
    "#         # Find the date of transmission of the archived files\n",
    "#         archive_date = self.__format_archive_date()\n",
    "\n",
    "#         # Loop through all rows of the table\n",
    "#         for row in archive_times.find_all('tr'):\n",
    "\n",
    "#             # Grab the end time, contained in the row's second <td> tag\n",
    "#             file_end_time = self.__time_to_hhmm(row.find_all('td')[1].text) \n",
    "\n",
    "#             # Represent the date & end time of the file as YYYYMMDD-HHMM\n",
    "#             file_end_date_time = '-'.join([archive_date, file_end_time])\n",
    "\n",
    "#             # Grab the file ID\n",
    "#             file_uri = row.find('a')['href'].split('/')[-1]\n",
    "\n",
    "#             # Put the file date/time and URL leaf (as a list) into the list\n",
    "#             table_entry_builder.append([file_uri, file_end_date_time])\n",
    "        \n",
    "#         return table_entry_builder\n",
    "\n",
    "    def __get_mp3_urls(self):\n",
    "        # Get the first page\n",
    "        parent.last_page_request_time = timer()\n",
    "        browser.get('https://m.broadcastify.com/archives/id/' + self.table_entries[0][1])\n",
    "\n",
    "\n",
    "#         # Log in so we can download files\n",
    "#         ## Store the fields for username + password\n",
    "#         username_field = browser.find_element_by_id(\"signinSrEmail\") \n",
    "#         password_field = browser.find_element_by_id(\"signinSrPassword\")\n",
    "\n",
    "#         ## Type username + password, and hit \"enter\"\n",
    "#         username_field.send_keys(USERNAME)\n",
    "#         password_field.send_keys(PASSWORD)\n",
    "#         password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "#         ## Wait for login to complete\n",
    "#         browser.implicitly_wait(2)\n",
    "\n",
    "        # Get the filepath for the mp3 archive\n",
    "        self.table_entries[0].append(get_mp3_path(BeautifulSoup(browser.page_source, 'lxml')))\n",
    "\n",
    "        for row in self.table_entries[1:11]:\n",
    "           # Wait until some time has passed, out of courtesy\n",
    "            while not courtesy_wait(parent.last_page_request_time): pass\n",
    "\n",
    "            # Get the next archive page, recording the time\n",
    "            browser.get('https://m.broadcastify.com/archives/id/' + row[1])\n",
    "            parent.last_page_request_time = timer()\n",
    "\n",
    "            # Get the filepath for the mp3 archive\n",
    "            row.append(get_mp3_path(BeautifulSoup(browser.page_source, 'lxml')))\n",
    "        \n",
    "    def __format_archive_date(self):\n",
    "\n",
    "        # Extract the day, month, and year of the data displayed on the page\n",
    "        day = self.soup.find('td', {'class': 'active day'}).text\n",
    "        month, year = self.soup.find('th', {'class': 'datepicker-switch'}).text.split()\n",
    "\n",
    "        # Format the date as YYYYMMDD\n",
    "        formatted_date = str(year) + str(MONTHS.index(month)).zfill(2) + day.zfill(2)\n",
    "\n",
    "        return formatted_date\n",
    "    \n",
    "    def __time_to_hhmm(self, s):\n",
    "        # More details, since it's a one-line method and this isn't freaking codewars:\n",
    "            # strptime converts the string to datetime \n",
    "                # see https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior\n",
    "                # and https://stackoverflow.com/questions/19229190/convert-12-hour-into-24-hour-times\n",
    "            # first split separates YYYY-MM-DD from HH:MM\n",
    "            # second split gets rid of the colon between HH & MM\n",
    "            # join puts HHMM together\n",
    "        # Converts a string representing a time in HH:MM AM/PM format to a string in 24-hr HHMM\n",
    "        return ''.join(str(datetime.strptime(s, '%I:%M %p')).split(' ')[-1].split(':')[:2])\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return (f'ArchiveTimesTable({len(self.table_entries)} entries)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "TEST_MP3_OUT_PATH = DATA_PATH + 'test_data/test_mp3/'\n",
    "\n",
    "TEST_FEED_ID = '18812'\n",
    "\n",
    "USERNAME = 'cwchiu'\n",
    "PASSWORD = 'datascientists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 1, 27, 23, 44, 40, 970724)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today() - timedelta(days=181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "atn = ArchiveTimesNavigator(ARCHIVE_URL_STEM + TEST_FEED_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//td[@class='old day' and contains(text(), '21')]\"}\n  (Session info: chrome=75.0.3770.142)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-681-6595d634508b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick_prior_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-674-667b539c85b7>\u001b[0m in \u001b[0;36mclick_prior_day\u001b[0;34m(self, n_days)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# click the day before the currently displayed day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         calendar_day = self.browser.find_element_by_xpath(\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0;34mf\"//td[@class='{xpath_class}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                         f\"and contains(text(), '{xpath_day}')]\")\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# https://stackoverflow.com/questions/2009268/how-to-write-an-xpath-query-to-match-two-attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//td[@class='old day' and contains(text(), '21')]\"}\n  (Session info: chrome=75.0.3770.142)\n"
     ]
    }
   ],
   "source": [
    "atn.click_prior_day()\n",
    "print(atn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-619-54ba693b9a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feed' is not defined"
     ]
    }
   ],
   "source": [
    "feed.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "del feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = BroadcastifyFeed(TEST_FEED_ID, USERNAME, PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete method called.\n"
     ]
    }
   ],
   "source": [
    "feed.archive.get_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['773831530', '20190727-1709'], ['773823986', '20190727-1639'], ['773817481', '20190727-1609'], ['773810895', '20190727-1539'], ['773805010', '20190727-1510'], ['773798449', '20190727-1440'], ['773790308', '20190727-1410'], ['773784180', '20190727-1340'], ['773777042', '20190727-1310'], ['773771190', '20190727-1240'], ['773765214', '20190727-1210'], ['773757101', '20190727-1141'], ['773750826', '20190727-1111'], ['773744097', '20190727-1041'], ['773737164', '20190727-1011'], ['773730937', '20190727-0941'], ['773723651', '20190727-0911'], ['773717272', '20190727-0842'], ['773710499', '20190727-0812'], ['773704908', '20190727-0742'], ['773697273', '20190727-0712'], ['773690608', '20190727-0642'], ['773682878', '20190727-0612'], ['773676590', '20190727-0543'], ['773669644', '20190727-0513'], ['773663813', '20190727-0443'], ['773657360', '20190727-0413'], ['773650877', '20190727-0343'], ['773643565', '20190727-0313'], ['773637411', '20190727-0244'], ['773629449', '20190727-0214'], ['773623537', '20190727-0144'], ['773616859', '20190727-0114'], ['773609142', '20190727-0044'], ['773602598', '20190727-0014']]\n"
     ]
    }
   ],
   "source": [
    "print(feed.archive.archive_times_table.table_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564263563.226176"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.last_file_request_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed.archive.last_file_request_time = 'foobar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foobar'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.archive.last_file_request_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "555px",
    "left": "918px",
    "right": "20px",
    "top": "41px",
    "width": "514px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
