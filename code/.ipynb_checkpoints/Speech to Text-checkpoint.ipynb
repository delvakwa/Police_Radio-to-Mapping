{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install google\n",
    "# ! pip install --user google.cloud\n",
    "# ! pip install --user google.cloud.speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Pickles/streets.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c62e4b096ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/Pickles/streets.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mstreets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Pickles/streets.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"../data/Pickles/streets.pkl\", \"rb\") as fp:\n",
    "    streets = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./api_key.json\"   \n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Street Name Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desired_files(directory_name):\n",
    "    desired_files = []\n",
    "    for filename in os.listdir(directory_name):\n",
    "        if (os.path.getsize(directory_name + '/' + filename) < 2_600_000) \n",
    "                                                & (filename.endswith('.wav')):\n",
    "            desired_files.append(directory_name + '/' + filename)\n",
    "    return desired_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_context(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\",\n",
    "        speech_contexts = [{\n",
    "                        \"phrases\": np.random.choice(streets, 5000)\n",
    "                         }]\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects speech in the audio file\n",
    "def transcribe_audio_context(config, audio):\n",
    "    \n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(1)\n",
    "    return transcript, confidence, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts_context = pool.map(transcribe_audio_context, \n",
    "                                       get_desired_files('../audio_data/audio_files/wav_files/'))\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "captions_context = [a[0] for a in list_of_transcripts_context if a[0] != '']\n",
    "confidence_context = [a[1] for a in list_of_transcripts_context if a[0] != '']\n",
    "names_context = [a[2] for a in list_of_transcripts_context if a[0] != '']\n",
    "\n",
    "data_context = {'transcripts': captions_context, \n",
    "                'confidence': confidence_context}\n",
    "df_context = pd.DataFrame(data_context)\n",
    "df_context.to_csv('../data/Data/transcribed_radio_with_street_context.csv')\n",
    "df_context.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_context['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Street Name Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_file_prep(file_name):\n",
    "    transcript = ''\n",
    "    conf = 0\n",
    "    # Loads the audio into memory\n",
    "    with io.open(file_name, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    #speech_to_text\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        model=\"video\"\n",
    "    )\n",
    "\n",
    "    return config, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Detects speech in the audio file\n",
    "def transcribe_audio(config, audio):\n",
    "    \n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "\n",
    "    time.sleep(3)\n",
    "    \n",
    "    return transcript, confidence, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(12) \n",
    "\n",
    "list_of_transcripts = pool.map(transcribe_audio, \n",
    "                               audio_file_prep('../audio_data/audio_files/wav_files/'))\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "captions = [a[0] for a in list_of_transcripts if a[0] != '']\n",
    "confidence = [a[1] for a in list_of_transcripts if a[0] != '']\n",
    "names = [a[2] for a in list_of_transcripts if a[0] != '']\n",
    "\n",
    "data = {'transcripts': captions, \n",
    "        'confidence': confidence}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('../data/Data/transcribed_radio.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Code adopted from [NY General Assembly DSI radio-to-location repository](https://github.com/mchbmn/radio-to-location)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
