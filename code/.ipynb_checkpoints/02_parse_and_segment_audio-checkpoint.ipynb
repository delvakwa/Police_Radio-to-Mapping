{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing background package and importing libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydub\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence, detect_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub.AudioSegment.converter = r\"C:/Users/kwama/Downloads/ffmpeg/ffmpeg/bin/ffmpeg.exe\"\n",
    "pydub.AudioSegment.ffmpeg = r\"C:/Users/kwama/Downloads/ffmpeg/ffmpeg/bin/ffmpeg.exe\"\n",
    "pydub.AudioSegment.ffprobe = r\"C:/Users/kwama/Downloads/ffmpeg/ffmpeg/bin/ffprobe.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the pydub Python package to parse and segment our mp3 files. Pydub accepts mp3 files and has methods that detect silence, detect audio, and split the mp3 files based on silence. We utilized the last method to pull samples of audio from our data. There are two parameters we passed in as well -- min_silence_len and silence_thresh. These determine how long a pause needs to be in milliseconds before itâ€™s registered as silence, and how loud something needs to be in dbFS before its registered as audio. We played with a few min_silence_len and silence_thresh values, but settled on 2.5 seconds and -16dbFS for our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_width= 2\n",
      "channel_count= 1\n",
      "duration_in_sec= 1897.822\n",
      "frame_rate= 22050\n"
     ]
    }
   ],
   "source": [
    "sound_file = AudioSegment.from_file(\"audio_data/audio_files/mp3_files/18812-20190725-0030.mp3\", format=\"mp3\")\n",
    "channel_count = sound_file.channels    \n",
    "sample_width = sound_file.sample_width \n",
    "duration_in_sec = len(sound_file) / 1000 \n",
    "sample_rate = sound_file.frame_rate\n",
    "\n",
    "print (\"sample_width=\", sample_width)\n",
    "print (\"channel_count=\", channel_count)\n",
    "print (\"duration_in_sec=\", duration_in_sec)\n",
    "print (\"frame_rate=\", sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.listdir('audio_data/audio_files/mp3_files/')[1]\n",
    "filename = 'audio_data/audio_files/mp3_files/' + file\n",
    "audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "audio_chunks = split_on_silence(audio, \n",
    "                              min_silence_len = 2_500,  #milliseconds          \n",
    "                              silence_thresh = -16)\n",
    "\n",
    "# mkdir f'wav samples for {file}' ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts audio samples that are between 1 second and 60 seconds long from mp3 to wav format. Google Speech to Text API accepts wav files, not mp3 files, and only allows for a total of 60 minutes of API use before you have to start paying for their services. We took that into account when deciding how long to make our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converst and adds audio samples that are between 1 and 60 seconds long \n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "    if (len(chunk) > 1000) and (len(chunk) < 60_000):\n",
    "        fn = f\"./audio_data/audio_files/wav_files/{file.split('.')[0]}_{i}.wav\"\n",
    "        chunk.export(fn, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Code adopted from [NY General Assembly DSI radio-to-location repository](https://github.com/mchbmn/radio-to-location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
